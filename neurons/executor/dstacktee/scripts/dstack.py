#!/usr/bin/env python3

import argparse
import json
import logging
import os
import random
import re
import subprocess
import uuid
import configparser
import host_api
import threading
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Optional
from functools import reduce

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def generate_config_paths():
    paths = [
        "/etc/dstack/client.conf",
        os.path.expanduser("~/.config/dstack/client.conf"),
    ]
    current_dir = os.getcwd()
    while current_dir != "/":
        paths.append(os.path.join(current_dir, ".dstack", "client.conf"))
        current_dir = os.path.dirname(current_dir)
    return paths


def merge2(a, b):
    if isinstance(a, dict) and isinstance(b, dict):
        c = a.copy()
        for k, v in b.items():
            c[k] = merge2(a.get(k), v)
        return c
    if b is None:
        return a
    return b


def test_merge2():
    assert merge2({"a": 1}, {"b": 2}) == {"a": 1, "b": 2}
    assert merge2({"a": 1}, {"a": 2}) == {"a": 2}
    assert merge2({"a": {"b": 1}}, {"a": {"c": 2}}) == {"a": {"b": 1, "c": 2}}


def merge_dicts(*dicts):
    return reduce(merge2, dicts, {})


def test_merge_dicts():
    assert merge_dicts({"a": 1}, {"b": 2}) == {"a": 1, "b": 2}
    assert merge_dicts({"a": 1}, {"a": 2}) == {"a": 2}
    assert merge_dicts({"a": {"b": 1}}, {"a": {"c": 2}}) == {"a": {"b": 1, "c": 2}}
    assert merge_dicts({"a": {"b": 1}}, {"a": {"b": 2}}) == {"a": {"b": 2}}
    assert merge_dicts({"a": {"b": 1}}, {"a": {"b": 2}, "c": 3}) == {
        "a": {"b": 2},
        "c": 3,
    }
    assert merge_dicts({"a": 1}, {"b": 2}, {"c": 3}) == {"a": 1, "b": 2, "c": 3}
    assert merge_dicts({"a": 1}, {"a": 2}, {"c": 3}) == {"a": 2, "c": 3}


def round_up(value, multiple):
    """
    Round up a value to the nearest multiple of another value.
    If the value is already a multiple, it remains unchanged.

    Args:
        value (int): The value to round up
        multiple (int): The multiple to round up to

    Returns:
        int: The rounded up value
    """
    if multiple <= 1:
        return value

    remainder = value % multiple
    if remainder == 0:
        return value

    return value + (multiple - remainder)


def ini_to_dict(filename):
    config = configparser.ConfigParser()
    config.read(filename)

    result = {}
    for section in config.sections():
        result[section] = {}
        for key, value in config.items(section):
            result[section][key] = value
    return result


def load_configs_merged(config_paths):
    config = {}
    for config_path in config_paths:
        if os.path.exists(config_path):
            logger.info(f"Loading configuration from {config_path}")
            config = merge_dicts(config, ini_to_dict(config_path))
    return config


def update_guest_config(config_file: str, data: Dict):
    if not os.path.exists(config_file):
        config = {}
    else:
        with open(config_file, "r") as f:
            config = json.load(f)
    config.update(data)
    with open(config_file, "w") as f:
        json.dump(config, f, indent=4)


class QemuConfig:
    def __init__(self):
        self.single_pass_add_pages = False
        self.pic = True
        self.smm = False
        self.pci_hole64_size = 0x100000000000
        self.hotplug_off = True

        qemu_version = get_qemu_version()
        if qemu_version:
            if (8, 0, 0) <= qemu_version <= (9, 0, 0):
                self.single_pass_add_pages = True
            if qemu_version >= (9, 0, 0):
                self.pic = False


def gen_vm_config(vm_dir, host_port, manifest=None, os_image_hash=None):
    shared_dir = os.path.join(vm_dir, "shared")
    for filename in ["config.json", ".sys-config.json"]:
        config_file = os.path.join(shared_dir, filename)
        update_guest_config(
            config_file,
            {
                "host_api_url": f"http://10.0.2.2:{host_port}/api",
                "host_vsock_port": host_port,
            },
        )
        if manifest:
            # Calculate GPU and NVSwitch counts from manifest
            gpus_cfg = manifest.get("gpus") or {}
            num_gpus = len(gpus_cfg.get("gpus") or [])
            num_nvswitches = len(gpus_cfg.get("bridges") or [])

            qemu_cfg = QemuConfig()
            qemu_version_str = get_qemu_version_string()
            update_guest_config(
                config_file,
                {
                    "vm_config": json.dumps(
                        {
                            "spec_version": 1,
                            "os_image_hash": os_image_hash,
                            "cpu_count": manifest["vcpu"],
                            "memory_size": manifest["memory"] * 1024 * 1024,
                            "qemu_single_pass_add_pages": qemu_cfg.single_pass_add_pages,
                            "pic": qemu_cfg.pic,
                            "pci_hole64_size": qemu_cfg.pci_hole64_size,
                            "num_gpus": num_gpus,
                            "num_nvswitches": num_nvswitches,
                            "hugepages": False,
                            "hotplug_off": qemu_cfg.hotplug_off,
                            "qemu_version": qemu_version_str,
                            "image": manifest.get("image"),
                        }
                    )
                },
            )


@dataclass
class DStackConfig:
    """Configuration for DStack client."""

    docker_registry: Optional[str] = None
    default_image_name: str = ""
    qemu_path: str = "qemu-system-x86_64"

    @classmethod
    def load(cls) -> "DStackConfig":
        """Load configuration from file."""
        cfgs = load_configs_merged(generate_config_paths())

        def cfg_get(section, key, fallback):
            if section in cfgs and key in cfgs[section]:
                return cfgs[section][key]
            return fallback

        me = cls()
        me.docker_registry = cfg_get("docker", "registry", cls.docker_registry)
        me.default_image_name = cfg_get("image", "default", cls.default_image_name)
        me.qemu_path = cfg_get("qemu", "path", cls.qemu_path)
        return me


class DStackManager:
    def __init__(self):
        self.run_path = os.path.abspath(os.getenv("RUN_PATH", "./vms"))
        self.config = DStackConfig.load()

    def _generate_instance_id(self) -> str:
        """Generate a random instance ID."""
        return str(uuid.uuid4())

    def _read_compose_file(self, compose_file: str) -> str:
        """Read and validate compose file."""
        if not os.path.isfile(compose_file):
            raise FileNotFoundError(f"Compose file not found: {compose_file}")
        with open(compose_file, "r") as f:
            return f.read()

    def _create_directories(self, work_dir: str) -> tuple[str, str]:
        """Create necessary directories."""
        if os.path.exists(work_dir):
            raise FileExistsError(f"The instance already exists at {work_dir}")

        shared_dir = os.path.join(work_dir, "shared")
        certs_dir = os.path.join(shared_dir, "certs")
        os.makedirs(shared_dir, exist_ok=True)
        os.makedirs(certs_dir, exist_ok=True)
        return shared_dir, certs_dir

    def _convert_memory_to_mb(self, memory: str) -> int:
        """Convert memory string to MB."""
        if memory.upper().endswith("T"):
            return int(memory[:-1]) * 1024 * 1024
        if memory.upper().endswith("G"):
            return int(memory[:-1]) * 1024
        if memory.upper().endswith("M"):
            return int(memory[:-1])
        return int(memory)

    def _parse_port_mapping(self, port_str: str) -> dict:
        """Parse port mapping string in format 'protocol[:address]:from:to'."""
        try:
            parts = port_str.split(":")
            if len(parts) == 3:
                proto, from_port, to_port = parts
                address = "127.0.0.1"  # default to localhost
            elif len(parts) == 4:
                proto, address, from_port, to_port = parts
            else:
                raise ValueError(
                    "Invalid port mapping format. Use 'protocol[:address]:from:to'"
                )

            return {
                "address": address,
                "protocol": proto.lower(),
                "from": int(from_port),
                "to": int(to_port),
            }
        except ValueError as e:
            raise ValueError(f"Invalid port mapping '{port_str}': {str(e)}")

    def setup_instance(self, args: argparse.Namespace) -> None:
        """Set up a new instance with the provided configuration."""
        try:
            # Generate instance ID if work_dir not provided
            instance_id = (
                os.path.basename(args.dir) if args.dir else self._generate_instance_id()
            )
            work_dir = args.dir or os.path.join(self.run_path, instance_id)

            # Create directories
            shared_dir, certs_dir = self._create_directories(work_dir)

            # Read compose file
            compose_content = self._read_compose_file(args.compose_file)

            # Create app-compose.json
            app_compose = {
                "manifest_version": 1,
                "name": "example",
                "version": "1.0.0",
                "features": [],
                "runner": "docker-compose",
                "docker_compose_file": compose_content,
                "local_key_provider_enabled": args.local_key_provider,
                "secure_time": False,
            }
            if args.init_script:
                app_compose["init_script"] = open(args.init_script, "r").read()
            if args.pre_launch_script:
                app_compose["pre_launch_script"] = open(
                    args.pre_launch_script, "r"
                ).read()
            with open(os.path.join(shared_dir, "app-compose.json"), "w") as f:
                json.dump(app_compose, f, indent=4)
            # Read image metadata and create config.json

            if self.config.docker_registry:
                update_guest_config(
                    os.path.join(shared_dir, ".sys-config.json"),
                    {
                        "docker_registry": self.config.docker_registry,
                    },
                )

            # Handle env file if provided
            if args.env_file:
                self._write_user_config(shared_dir, args.env_file)

            # Create VM manifest
            memory = self._convert_memory_to_mb(str(args.memory))
            disk_size = self._convert_memory_to_mb(str(args.disk)) // 1024
            port_map = []
            if args.port:
                for port_str in args.port:
                    port_map.append(self._parse_port_mapping(port_str))

            if args.gpu == ["all"]:
                gpus = {
                    "attach_mode": "all",
                }
            else:
                gpus = {
                    "attach_mode": "listed",
                    "gpus": [{"slot": gpu} for gpu in args.gpu or []],
                }
            gpus = self.resolve_gpus(gpus)
            vm_config = {
                "id": instance_id,
                "name": "",
                "vcpu": args.vcpus,
                "gpus": gpus,
                "memory": memory,
                "disk_size": disk_size,
                "image_path": args.image,
                "image": os.path.basename(args.image.rstrip("/")),
                "port_map": port_map,
                "pin_numa": args.pin_numa,
                "hugepages": args.hugepages,
                "created_at_ms": int(datetime.now().timestamp() * 1000),
            }
            with open(os.path.join(work_dir, "vm-manifest.json"), "w") as f:
                json.dump(vm_config, f, indent=4)
            logger.info(f"Work directory prepared successfully at: {work_dir}")

        except Exception as e:
            logger.error(f"Failed to setup instance: {str(e)}")
            raise

    def _write_user_config(self, shared_dir: str, env_file_path: str) -> None:
        """Write user-config.json with env file parsed as JSON key-value pairs."""
        if not os.path.isfile(env_file_path):
            raise FileNotFoundError(f"Env file not found: {env_file_path}")

        # Parse .env file into a dictionary (safe parsing, no code execution)
        env_dict = {}
        with open(env_file_path, "r", encoding="utf-8") as f:
            for line_no, line in enumerate(f, 1):
                line = line.strip()
                # Skip empty lines and comments
                if not line or line.startswith('#'):
                    continue
                # Skip lines without '='
                if '=' not in line:
                    logger.warning(f"Skipping malformed line {line_no} in {env_file_path}")
                    continue
                # Split on first '=' only
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip()
                
                # Remove inline comments (e.g., "value # comment")
                # Only strip comments if not inside quotes
                if '#' in value:
                    # Check if value starts with quote
                    if value and value[0] in ('"', "'"):
                        quote_char = value[0]
                        # Find closing quote
                        closing_quote_idx = value.find(quote_char, 1)
                        if closing_quote_idx > 0:
                            # Keep only quoted part
                            value = value[:closing_quote_idx + 1]
                    else:
                        # No quotes, strip everything after #
                        value = value.split('#')[0].strip()
                
                # Remove quotes if present
                if len(value) >= 2 and value[0] == value[-1] and value[0] in ('"', "'"):
                    value = value[1:-1]
                env_dict[key] = value

        user_config_path = os.path.join(shared_dir, ".user-config")
        user_config = {}

        # Load existing user-config.json if it exists
        if os.path.exists(user_config_path):
            try:
                with open(user_config_path, "r", encoding="utf-8") as f:
                    user_config = json.load(f)
            except (json.JSONDecodeError, IOError):
                logger.warning(
                    f"Could not read existing {user_config_path}, creating new one"
                )
                user_config = {}

        # Add env file as JSON object
        user_config["env_vars"] = env_dict

        # Write updated user-config.json
        with open(user_config_path, "w", encoding="utf-8") as f:
            json.dump(user_config, f, indent=4)

        logger.info(f"Env file parsed to JSON and written to {user_config_path}")

    @staticmethod
    def collect_all_gpus() -> dict:
        """Collect available NVIDIA GPUs and NVSwitches."""
        try:
            # Find all NVIDIA GPUs (3D controllers)
            gpu_cmd = subprocess.run(
                ["lspci", "-d", "10de:", "-nn"],
                capture_output=True,
                text=True,
                check=True,
            )
            gpu_output = gpu_cmd.stdout.strip()

            gpus = []
            bridges = []

            # Process each line of output
            for line in gpu_output.split("\n"):
                if not line.strip():
                    continue

                slot = line.split()[0]  # Bus:Device.Function

                # Extract device ID from the line
                match = re.search(r"\[10de:([0-9A-Fa-f]+)\]", line)
                if not match:
                    continue
                # Check if it's a GPU (3D controller) or NVSwitch (Bridge)
                if "3D controller" in line:
                    gpus.append(
                        {
                            "slot": slot,
                        }
                    )
                elif "Bridge" in line:
                    bridges.append(
                        {
                            "slot": slot,
                        }
                    )

            logger.info(f"Found {len(gpus)} GPU(s) and {len(bridges)} NVSwitch(es)")

            return {"attach_mode": "all", "gpus": gpus, "bridges": bridges}
        except subprocess.SubprocessError as e:
            logger.warning(f"Failed to collect GPU information: {str(e)}")
            return {"attach_mode": "all", "gpus": [], "bridges": []}

    @staticmethod
    def resolve_gpus(gpus: dict) -> dict:
        """Resolve GPU slots."""
        match gpus["attach_mode"]:
            case "listed":
                return gpus
            case "all":
                return DStackManager.collect_all_gpus()
            case _:
                raise ValueError(f"Invalid GPU attach mode: {gpus['attach_mode']}")

    def run_instance(
        self,
        vm_dir: str,
        host_port: int,
        imgdir: Optional[str] = None,
        dry_run: bool = False,
    ) -> None:
        """Run a VM instance from the specified directory.

        Args:
            vm_dir: Directory containing the VM configuration
            dry_run: Whether to run in dry run mode
        """

        manifest_path = os.path.join(vm_dir, "vm-manifest.json")
        if not os.path.exists(manifest_path):
            raise ValueError(f"VM manifest not found in {vm_dir}")

        with open(manifest_path, "r") as f:
            manifest = json.load(f)

        if dry_run:
            print("Manifest:")
            print(json.dumps(manifest, indent=4))

        # Get image path and metadata
        image_path = manifest.get("image_path") or os.path.join(
            imgdir, manifest["image"]
        )
        img_metadata_path = os.path.join(image_path, "metadata.json")

        if not os.path.exists(img_metadata_path):
            raise ValueError(f"Image metadata not found at {img_metadata_path}")

        with open(img_metadata_path, "r") as f:
            img_metadata = json.load(f)

        os_image_hash = open(os.path.join(image_path, "digest.txt"), "r").read().strip()
        gen_vm_config(vm_dir, host_port, manifest, os_image_hash)

        mem_gb = manifest["memory"] // 1024
        vcpu_count = manifest["vcpu"]
        disk_size = manifest["disk_size"]

        vda = os.path.join(vm_dir, "hda.img")
        config_dir = os.path.join(vm_dir, "shared")

        # Create disk if it doesn't exist
        if not os.path.exists(vda):
            subprocess.run(
                ["qemu-img", "create", "-f", "qcow2", vda, f"{disk_size}G"], check=True
            )

        cid = random.randint(1, 10000) + 3

        # Prepare QEMU command
        cmd_args = []
        rootfs_image = os.path.join(image_path, img_metadata["rootfs"])
        if rootfs_image.endswith(".img.verity"):
            cmd_args.extend(
                [
                    "-drive",
                    f"file={rootfs_image},if=none,id=virtio-disk0,format=raw,readonly=on",
                    "-device",
                    "virtio-blk-pci,drive=virtio-disk0",
                ]
            )
        elif rootfs_image.endswith(".img"):
            cmd_args.extend(["-cdrom", rootfs_image])
        else:
            raise ValueError(f"Unsupported rootfs image format: {rootfs_image}")
        cmd_args.extend(["-drive", f"file={vda},if=none,id=virtio-disk1"])
        cmd_args.extend(["-device", "virtio-blk-pci,drive=virtio-disk1"])
        qemu_cfg = QemuConfig()
        if qemu_cfg.hotplug_off:
            cmd_args.extend(
                [
                    "-global",
                    "ICH9-LPC.acpi-pci-hotplug-with-bridge-support=off",
                ]
            )
        if qemu_cfg.pci_hole64_size > 0:
            cmd_args.extend(
                [
                    "-global",
                    f"q35-pcihost.pci-hole64-size=0x{qemu_cfg.pci_hole64_size:x}",
                ]
            )

        # Add network configuration
        port_args = []
        for port_map in manifest.get("port_map", []):
            protocol = port_map.get("protocol", "tcp")
            bind_address = port_map.get("address", "127.0.0.1")
            host_port = port_map["from"]
            vm_port = port_map["to"]
            port_args.append(
                f"hostfwd={protocol}:{bind_address}:{host_port}-:{vm_port}"
            )
        cmd_args.extend(
            [
                "-device",
                "virtio-net-pci,netdev=nic0_td",
                "-netdev",
                f"user,id=nic0_td{',' + ','.join(port_args) if len(port_args) > 0 else ''}",
            ]
        )

        # Handle GPUs
        gpus_cfg = manifest.get("gpus") or {}
        gpus = gpus_cfg.get("gpus") or []
        bridges = gpus_cfg.get("bridges") or []
        dev_num = 1
        hugepages = manifest.get("hugepages", False)
        if hugepages:
            numa_nodes = {}
            if gpus:
                for dev in gpus:
                    node = numa_node_of_device(dev["slot"])
                    if node not in numa_nodes:
                        numa_nodes[node] = 0
                    numa_nodes[node] += 1
            else:
                numa_nodes[0] = 0
            n_numa = len(numa_nodes)
            # Round up cpu cores and memory to multiple times of numa nodes
            vcpu_count = round_up(vcpu_count, n_numa)
            mem_gb = round_up(mem_gb, n_numa)
            vcpu_per_node = vcpu_count // n_numa
            mem_per_node = mem_gb // n_numa

            bus_nr = 5
            for ind, (node, count) in enumerate(numa_nodes.items()):
                cmd_args.extend(
                    [
                        "-numa",
                        f"node,nodeid={ind},cpus={ind * vcpu_per_node}-{(ind + 1) * vcpu_per_node - 1},memdev=mem{ind}",
                        "-object",
                        f"memory-backend-file,id=mem{ind},size={mem_per_node}G,mem-path=/dev/hugepages,share=on,prealloc=yes,host-nodes={node},policy=bind",
                        "-device",
                        f"pxb-pcie,id=pcie.node{node},bus=pcie.0,addr={0xA + ind},numa_node={ind},bus_nr={bus_nr}",
                    ]
                )
                bus_nr += count + 1
        if gpus:
            cmd_args.extend(["-object", "iommufd,id=iommufd0"])
            if not hugepages:
                for dev in gpus:
                    slot = dev["slot"]
                    cmd_args.extend(
                        [
                            "-device",
                            f"pcie-root-port,id=pci.{dev_num},bus=pcie.0,chassis={dev_num}",
                            "-device",
                            f"vfio-pci,host={slot},bus=pci.{dev_num},iommufd=iommufd0",
                        ]
                    )
                    dev_num += 1
            else:
                for dev in gpus:
                    slot = dev["slot"]
                    node = numa_node_of_device(slot)
                    cmd_args.extend(
                        [
                            "-device",
                            f"pcie-root-port,id=pci.{dev_num},bus=pcie.node{node},chassis={dev_num}",
                            "-device",
                            f"vfio-pci,host={slot},bus=pci.{dev_num},iommufd=iommufd0",
                        ]
                    )
                    dev_num += 1
            for bridge in bridges:
                slot = bridge["slot"]
                cmd_args.extend(
                    [
                        "-device",
                        f"pcie-root-port,id=pci.{dev_num},bus=pcie.0,chassis={dev_num}",
                        "-device",
                        f"vfio-pci,host={slot},bus=pci.{dev_num},iommufd=iommufd0",
                    ]
                )
                dev_num += 1
        # Add kernel command line
        cmd_args.extend(["-append", img_metadata["cmdline"]])

        machine = "q35,kernel_irqchip=split,confidential-guest-support=tdx,hpet=off"
        if qemu_cfg.smm:
            machine += ",smm=on"
        else:
            machine += ",smm=off"

        base_args = [
            self.config.qemu_path,
            "-accel",
            "kvm",
            "-m",
            f"{mem_gb}G",
            "-smp",
            str(vcpu_count),
            "-cpu",
            "host",
            "-machine",
            machine,
            "-object",
            "tdx-guest,id=tdx",
            "-nographic",
            "-nodefaults",
            "-chardev",
            "stdio,id=ser0,signal=on",
            "-serial",
            "chardev:ser0",
            "-kernel",
            os.path.join(image_path, img_metadata["kernel"]),
            "-initrd",
            os.path.join(image_path, img_metadata["initrd"]),
            "-bios",
            os.path.join(image_path, img_metadata["bios"]),
            "-virtfs",
            f"local,path={config_dir},mount_tag=host-shared,readonly=off,security_model=mapped,id=virtfs0",
            "-device",
            f"vhost-vsock-pci,guest-cid={cid}",
        ]

        pin_numa = manifest.get("pin_numa", False)
        if pin_numa:
            if gpus:
                numa_node = numa_node_of_device(gpus[0]["slot"])
            else:
                numa_node = 0
            cpus = (
                open(f"/sys/devices/system/node/node{numa_node}/cpulist").read().strip()
            )
            base_args = ["taskset", "-c", cpus] + base_args
        cmd = base_args + cmd_args
        print(" \n".join(cmd))
        if dry_run:
            return
        # Run the command
        try:
            subprocess.run(cmd, check=True)
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Failed to start VM: {e}")


def numa_node_of_device(pci_slot):
    """
    Get the NUMA node associated with a PCI device.

    Args:
        pci_slot (str): PCI slot in format "domain:bus:device.function" (e.g., "0000:ab:00.0")

    Returns:
        int: NUMA node number, or -1 if device doesn't exist or has no NUMA affinity
    """
    # Normalize the PCI slot format if needed
    if not pci_slot.startswith("0000:"):
        pci_slot = f"0000:{pci_slot}"
    # Try to read NUMA node from sysfs
    numa_path = f"/sys/bus/pci/devices/{pci_slot}/numa_node"

    with open(numa_path, "r") as f:
        numa_node = int(f.read().strip())
        return numa_node


def list_available_gpus() -> None:
    """List available NVIDIA GPUs."""
    try:
        # Run lspci with verbose output to get detailed information
        result = subprocess.run(["lspci", "-vvk"], capture_output=True, text=True)
        output_lines = result.stdout.split("\n")

        # Find all GPU entries and their details
        gpu_blocks = []
        current_block = []
        in_gpu_block = False

        for line in output_lines:
            if "NVIDIA" in line and "3D controller" in line:
                # Start of a new GPU block
                if current_block:
                    gpu_blocks.append(current_block)
                current_block = [line]
                in_gpu_block = True
            elif in_gpu_block:
                if line.strip() == "" or (
                    line[0] != "\t" and line[0] != " " and len(current_block) > 1
                ):
                    # End of the current block
                    gpu_blocks.append(current_block)
                    current_block = []
                    in_gpu_block = False
                else:
                    # Continue adding lines to the current block
                    current_block.append(line)

        # Add the last block if it exists
        if current_block:
            gpu_blocks.append(current_block)

        if gpu_blocks:
            print("\nAvailable GPU IDs:")
            print("ID   Numa Node  In Use    Description")
            print("-------------------------------------")

            for block in gpu_blocks:
                # Extract device ID from the first line
                device_id = block[0].split()[0]
                description = block[0].split(":", 2)[2].strip()

                # Check if GPU is in use by examining Control line and Latency
                in_use = False
                for line in block:
                    if "Control:" in line and "I/O+" in line and "BusMaster+" in line:
                        in_use = True
                    elif "Latency:" in line:
                        in_use = True

                status = "Yes" if in_use else "No"
                node = numa_node_of_device(device_id)
                print(f"{device_id}   {node}   {status:8}  {description}")
            print()
    except subprocess.SubprocessError as e:
        logger.warning(f"Could not list GPU devices: {str(e)}")


def start_server(dir: str, kp_port: int):
    config = host_api.ServerConfig(vm_dir=dir, kp_address="127.0.0.1", kp_port=kp_port)
    api, host_port = host_api.create_http_server(config)
    print(f"Starting HTTP server on localhost:{host_port}")
    thread = threading.Thread(target=api.serve_forever, daemon=True)
    thread.host_port = host_port
    thread.start()
    return thread


def tag_vfio():
    """
    Tag NVIDIA GPUs and NVSwitches for VFIO passthrough.
    Detects NVIDIA devices and configures them for VFIO passthrough.
    """
    logging.info("==> Detecting NVIDIA GPUs and NVSwitches")

    try:
        # Use a more structured approach to detect devices
        devices = detect_nvidia_devices()

        if not devices["gpus"] and not devices["switches"]:
            logging.error("No NVIDIA GPUs or NVSwitches found. Exiting.")
            return

        ngpu = len(devices["gpus"])
        nsw = len(devices["switches"])

        logging.info(f"Found {ngpu} GPU(s)")
        logging.info(f"Found {nsw} NVSwitch(es)")

        # Load VFIO modules
        logging.info("==> Loading VFIO modules")
        load_vfio_modules()

        # Tag devices for VFIO passthrough
        logging.info("==> Tagging devices for VFIO passthrough")

        # Deduplicate device IDs
        unique_dev_ids = {}
        for device_type, device_list in devices.items():
            device_name = "GPU" if device_type == "gpus" else "NVSwitch"
            for device in device_list:
                dev_id = device["dev_id"]
                if dev_id not in unique_dev_ids:
                    unique_dev_ids[dev_id] = device_name
                # If the device ID is already in the dict but with a different type,
                # we'll keep the original type for simplicity

        # Process unique device IDs
        for dev_id, device_name in unique_dev_ids.items():
            tag_device_for_vfio(dev_id, device_name)

        logging.info("VFIO passthrough setup complete")

    except Exception as e:
        logging.error(f"Failed to enable VFIO passthrough: {e}")


def detect_nvidia_devices():
    """
    Detect NVIDIA GPUs and NVSwitches in the system.

    Returns:
        dict: Dictionary with 'gpus' and 'switches' keys, each containing a list of
              dictionaries with 'dev_id' for each device.
    """
    devices = {"gpus": [], "switches": []}

    try:
        # Run lspci once and parse the output
        lspci_output = (
            subprocess.check_output("lspci -d 10de: -nn", shell=True, text=True)
            .strip()
            .split("\n")
        )

        for line in lspci_output:
            if not line:
                continue

            # Extract Device ID
            dev_id_match = re.search(r"\[10de:([0-9A-Fa-f]+)\]", line)
            if not dev_id_match:
                continue

            dev_id = dev_id_match.group(1)

            # Categorize device
            if "3D controller" in line:
                devices["gpus"].append({"dev_id": dev_id})
            elif "Bridge" in line:
                devices["switches"].append({"dev_id": dev_id})

    except subprocess.CalledProcessError as e:
        logging.error(f"Failed to detect NVIDIA devices: {e}")

    return devices


def load_vfio_modules():
    """
    Load the VFIO kernel modules required for device passthrough.
    Assumes the script is run with appropriate permissions.

    Raises:
        RuntimeError: If modules cannot be loaded
    """
    try:
        subprocess.run(["modprobe", "vfio"], check=True)
        subprocess.run(["modprobe", "vfio_pci"], check=True)
    except subprocess.CalledProcessError as e:
        logging.error(f"Failed to load VFIO modules: {e}")
        raise RuntimeError("Failed to load VFIO modules") from e


def tag_device_for_vfio(dev_id, device_type):
    """
    Tag a PCI device for VFIO passthrough.

    Args:
        dev_id (str): Device ID
        device_type (str): Type of device (GPU or NVSwitch)
    """
    logging.info(f"Tagging {device_type} (DevID=10de:{dev_id})")

    new_id_path = "/sys/bus/pci/drivers/vfio-pci/new_id"
    remove_id_path = "/sys/bus/pci/drivers/vfio-pci/remove_id"
    device_id_value = f"10de {dev_id}"

    try:
        # Directly write to the sysfs file
        write_to_sysfs(new_id_path, device_id_value)
    except Exception:
        try:
            # Remove the ID first in case it's already there
            try:
                write_to_sysfs(remove_id_path, device_id_value)
            except Exception:
                # Ignore errors when removing
                pass

            # Try adding again
            write_to_sysfs(new_id_path, device_id_value)
        except Exception as e:
            logging.error(f"Failed to tag {device_type}: {e}")


def write_to_sysfs(path, value):
    """
    Write a value directly to a sysfs file.
    Assumes the script is run with appropriate permissions.

    Args:
        path (str): Path to the sysfs file
        value (str): Value to write

    Raises:
        IOError: If the write fails
    """
    with open(path, "w") as f:
        f.write(value)


def detect_qemu_version(qemu_path: str) -> Optional[str]:
    """
    Detect QEMU version by running qemu --version command.
    
    Args:
        qemu_path: Path to the QEMU executable
        
    Returns:
        str: QEMU version string (e.g., "8.2.2") or None if detection fails
    """
    try:
        result = subprocess.run(
            [qemu_path, "--version"], 
            capture_output=True, 
            text=True, 
            check=True
        )
        
        if not result.returncode == 0:
            logger.error(f"QEMU version command failed with status: {result.returncode}")
            return None
            
        version_output = result.stdout
        return parse_qemu_version_from_output(version_output)
        
    except subprocess.CalledProcessError as e:
        logger.error(f"Failed to execute qemu --version: {e}")
        return None
    except FileNotFoundError:
        logger.error(f"QEMU executable not found at path: {qemu_path}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error getting QEMU version: {e}")
        return None


def parse_qemu_version_from_output(output: str) -> Optional[str]:
    """
    Parse QEMU version from command output.
    
    Handles various output formats like:
    - "QEMU emulator version 8.2.2 (Debian 2:8.2.2+ds-0ubuntu1.4+tdx1.0)"
    - "QEMU emulator version 9.1.0"
    
    Args:
        output: Raw output from qemu --version command
        
    Returns:
        str: Clean version string (e.g., "8.2.2") or None if parsing fails
    """
    if not output:
        return None
        
    # Get the first line of output
    first_line = output.strip().split('\n')[0] if output.strip() else ""
    if not first_line:
        return None
        
    # Split into words for analysis
    words = first_line.split()
    
    # First try: Look for "version" keyword and get the next word (only if it looks like a version)
    try:
        version_idx = words.index("version")
        if version_idx + 1 < len(words):
            next_word = words[version_idx + 1]
            # Only use the word after "version" if it looks like a version number
            if (next_word and 
                next_word[0].isdigit() and 
                ('.' in next_word or next_word.replace('-', '').isdigit())):
                # Extract just the version number (e.g., "8.2.2" from "8.2.2+ds-0ubuntu1.4+tdx1.0")
                clean_version = next_word.split('+')[0]
                return clean_version
    except (ValueError, IndexError):
        pass
    
    # Fallback: find first word that looks like a version number
    for word in words:
        if (word and 
            word[0].isdigit() and 
            ('.' in word or word.replace('-', '').isdigit())):
            # Extract just the version number
            clean_version = word.split('+')[0]
            return clean_version
    
    logger.warning(f"Could not parse QEMU version from output: {output}")
    return None


def get_qemu_version() -> Optional[tuple]:
    """
    Get QEMU version as a tuple (major, minor, patch).

    Returns:
        tuple: Version tuple (major, minor, patch) or None if version cannot be determined
    """
    try:
        config = DStackConfig.load()
        qemu_path = config.qemu_path
        
        version_str = detect_qemu_version(qemu_path)
        if not version_str:
            return None
            
        # Parse version string into tuple
        version_parts = version_str.split('.')
        if len(version_parts) >= 2:
            try:
                major = int(version_parts[0])
                minor = int(version_parts[1])
                patch = int(version_parts[2]) if len(version_parts) > 2 else 0
                return (major, minor, patch)
            except ValueError:
                logger.warning(f"Could not parse version parts from: {version_str}")
                return None
        else:
            logger.warning(f"Invalid version format: {version_str}")
            return None
            
    except Exception as e:
        logger.error(f"Unexpected error getting QEMU version: {e}")
        return None


def get_qemu_version_string() -> Optional[str]:
    """
    Get QEMU version as a string.
    
    Returns:
        str: QEMU version string (e.g., "8.2.2") or None if version cannot be determined
    """
    try:
        config = DStackConfig.load()
        qemu_path = config.qemu_path
        return detect_qemu_version(qemu_path)
    except Exception as e:
        logger.error(f"Unexpected error getting QEMU version string: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description="DStack VM Management Tool")
    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # Setup command
    setup_parser = subparsers.add_parser("new", help="Setup a new instance")
    setup_parser.add_argument("compose_file", type=str, help="Docker compose file")
    setup_parser.add_argument("-o", "--dir", type=str, help="Work directory")
    setup_parser.add_argument("-i", "--image", type=str, help="VM image path")
    setup_parser.add_argument(
        "-c", "--vcpus", type=int, default=1, help="Number of vCPUs"
    )
    setup_parser.add_argument(
        "-m", "--memory", type=str, default="2G", help="Memory size (e.g., 1G, 512M)"
    )
    setup_parser.add_argument(
        "-d", "--disk", type=str, default="20G", help="Disk size (e.g., 20G)"
    )
    setup_parser.add_argument(
        "-g", "--gpu", type=str, action="append", help="GPU device"
    )
    setup_parser.add_argument(
        "-p",
        "--port",
        action="append",
        type=str,
        help="Port mapping in format: protocol[:address]:from:to",
    )
    setup_parser.add_argument(
        "--local-key-provider",
        "--lkp",
        action="store_true",
        help="Enable local key provider",
    )
    setup_parser.add_argument("--init-script", type=str, help="Init script path")
    setup_parser.add_argument(
        "--pre-launch-script", type=str, help="Pre-launch script path"
    )
    setup_parser.add_argument(
        "--env-file",
        type=str,
        help="Path to .env file to embed into vmdir/shared/user-config.json",
    )
    setup_parser.add_argument(
        "--pin-numa", action="store_true", help="Pin vCPUs to NUMA node"
    )
    setup_parser.add_argument(
        "--hugepages", action="store_true", help="Enable hugepages"
    )

    # Start command
    start_parser = subparsers.add_parser("run", help="Start an instance")
    start_parser.add_argument("dir", type=str, help="Work directory")
    start_parser.add_argument("--imgdir", type=str, help="The image directory")
    start_parser.add_argument(
        "--kp-port", type=int, default=3443, help="The key provider listening port"
    )
    start_parser.add_argument(
        "--dry-run", action="store_true", help="Run in dry run mode"
    )

    # List Gpus command
    subparsers.add_parser("lsgpu", help="List available GPUs")

    # Tag VFIO command
    subparsers.add_parser(
        "tag-vfio", help="Tag NVIDIA GPUs and NVSwitches for VFIO passthrough"
    )

    # Run the host server only
    serve_parser = subparsers.add_parser("serve", help="Run the host server only")
    serve_parser.add_argument("dir", type=str, help="Work directory")
    serve_parser.add_argument(
        "--kp-port", type=int, default=3443, help="The key provider listening port"
    )

    args = parser.parse_args()

    if args.command == "new":
        manager = DStackManager()
        manager.setup_instance(args)
    elif args.command == "run":
        manager = DStackManager()
        thread = start_server(args.dir, args.kp_port)
        manager.run_instance(
            args.dir, thread.host_port, imgdir=args.imgdir, dry_run=args.dry_run
        )
    elif args.command == "lsgpu":
        list_available_gpus()
    elif args.command == "tag-vfio":
        tag_vfio()
    elif args.command == "serve":
        thread = start_server(args.dir, args.kp_port)
        gen_vm_config(args.dir, thread.host_port)
        thread.join()
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
